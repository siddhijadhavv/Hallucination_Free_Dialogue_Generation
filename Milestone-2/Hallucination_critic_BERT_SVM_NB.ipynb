{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-multilearn datasets transformers --quiet"
      ],
      "metadata": {
        "id": "q_gHtePKxbpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00t8qXI-5FIz"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import string\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import torch\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import classification_report\n",
        "import requests\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
        "from sklearn.metrics import accuracy_score,hamming_loss\n",
        "from skmultilearn.problem_transform import BinaryRelevance, ClassifierChain, LabelPowerset\n",
        "import sklearn.metrics as skm\n",
        "from sklearn import metrics\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "pzbS43_fGFdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4ZUDKZ55FI0"
      },
      "outputs": [],
      "source": [
        "nlp=spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_BU9cr65FI1"
      },
      "outputs": [],
      "source": [
        "nlp.pipe_names"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_convert_data(api_url):\n",
        "  get_data = requests.get(api_url)\n",
        "  data = get_data.json()\n",
        "  dialog_idx = []\n",
        "  response = []\n",
        "  original_response = []\n",
        "  history = []\n",
        "  knowledge = []\n",
        "  Begin = []\n",
        "  vrm = []\n",
        "  headers = []\n",
        "  for i in data[\"rows\"]:\n",
        "    for key,value in i.items():\n",
        "      if type(value)!=int and type(value)!=list:\n",
        "        for k,v in value.items():\n",
        "          if k not in headers:\n",
        "            headers.append(k)\n",
        "          if k == \"dialog_idx\":\n",
        "            dialog_idx.append(v)\n",
        "          if k == \"response\":\n",
        "            response.append(v)\n",
        "          if k == \"original_response\":\n",
        "            original_response.append(v)\n",
        "          if k == \"history\":\n",
        "            history.append(v)\n",
        "          if k == \"knowledge\":\n",
        "            knowledge.append(v)\n",
        "          if k == \"BEGIN\":\n",
        "            Begin.append(v)\n",
        "          if k == \"VRM\":\n",
        "            vrm.append(v)\n",
        "  full_data = list(zip(dialog_idx,response,original_response,history,knowledge,Begin,vrm))\n",
        "  testing_data = pd.DataFrame(full_data, columns=headers)\n",
        "  return testing_data"
      ],
      "metadata": {
        "id": "GOBeJKV-EEIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxG_ts1H1uBc"
      },
      "outputs": [],
      "source": [
        "def clean_data(data):\n",
        "   for i in range(0,len(data)):\n",
        "      #Convert text to lower\n",
        "      if type(data.iloc[i]) == float:\n",
        "         data.iloc[i]= str(data.iloc[i])\n",
        "      data.iloc[i] = data.iloc[i].lower()\n",
        "      #Tokenize the data using spacy\n",
        "      doc = nlp(data.iloc[i])\n",
        "      #Convert data to lower using spacy\n",
        "      tokens = [tokens.lower_ for tokens in doc]\n",
        "      #remove stop words\n",
        "      tokens = [tokens for tokens in doc if (tokens.is_stop == False)]\n",
        "      #remove Punctuation\n",
        "      tokens = [tokens for tokens in tokens if (tokens.is_punct == False)]\n",
        "      #lemmatize the data\n",
        "      final_token = [token.lemma_ for token in tokens]\n",
        "      #generate the cleaned text\n",
        "      data.iloc[i] = \" \".join(final_token)\n",
        "   return data\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def label_data(new_df, columns):\n",
        "  mlb = MultiLabelBinarizer()\n",
        "  mlb_df = mlb.fit_transform(new_df[columns].to_numpy())\n",
        "  df_ohe = pd.DataFrame(mlb_df,new_df.index, mlb.classes_)\n",
        "  final_df = pd.concat([new_df,df_ohe], axis=1)\n",
        "  return final_df"
      ],
      "metadata": {
        "id": "20EhRifYRYih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_duplicates(history):\n",
        "  blist = [j for i in history for j in i]\n",
        "  alist = [] \n",
        "  for i in blist:\n",
        "    if i not in alist:\n",
        "      alist.append(i)\n",
        "  return alist"
      ],
      "metadata": {
        "id": "a-Ha9cTAJ3jM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_seeker(dataset):\n",
        "  resp_hist = dataset[[\"response\", \"history\"]]\n",
        "  response = resp_hist[\"response\"].to_numpy()\n",
        "  history =  resp_hist[\"history\"].to_numpy()\n",
        "  alist = remove_duplicates(history)\n",
        "  seeker= [i for i in alist if i not in response]\n",
        "  df = pd.DataFrame({'seeker':seeker})\n",
        "  new_df = pd.concat([dataset, df],axis =1)\n",
        "  return new_df"
      ],
      "metadata": {
        "id": "DgJ_2NVHJs1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainUrl = read_convert_data(\"https://datasets-server.huggingface.co/first-rows?dataset=McGill-NLP%2FFaithDial&config=plain_text&split=validation\")\n",
        "train_seeker = generate_seeker(trainUrl)\n",
        "final_train_1 = label_data(train_seeker, \"BEGIN\")\n",
        "final_train = label_data(final_train_1, \"VRM\")"
      ],
      "metadata": {
        "id": "H400HjYNK6_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testUrl=read_convert_data(\"https://datasets-server.huggingface.co/first-rows?dataset=McGill-NLP%2FFaithDial&config=plain_text&split=test\")\n",
        "test_seeker = generate_seeker(testUrl)\n",
        "final_test_1 = label_data(test_seeker, \"BEGIN\")\n",
        "final_test = label_data(final_test_1, \"VRM\")"
      ],
      "metadata": {
        "id": "4NWOVCZ3T2_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_data(final_train[\"knowledge\"])\n",
        "clean_data(final_train[\"response\"])\n",
        "clean_data(final_train[\"seeker\"])"
      ],
      "metadata": {
        "id": "gZAXSFziU4uJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_data(final_test[\"knowledge\"])\n",
        "clean_data(final_test[\"response\"])\n",
        "clean_data(final_test[\"seeker\"])"
      ],
      "metadata": {
        "id": "2y66ExY2WzEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_train"
      ],
      "metadata": {
        "id": "ueBb1w2_lR9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BERT Classifier"
      ],
      "metadata": {
        "id": "01j-WyqWvQ9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = final_train[[\"knowledge\", \"seeker\", \"response\"]]\n",
        "X_test = final_test[[\"knowledge\", \"seeker\", \"response\"]]\n",
        "y_train = final_train[[\"Entailment\",\"Generic\",\"Hallucination\",\"Uncooperative\"]]\n",
        "y_test = final_test[[\"Entailment\",\"Generic\",\"Hallucination\",\"Uncooperative\"]]"
      ],
      "metadata": {
        "id": "s3obwtzDum7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pipeline\n",
        "modelNb = BinaryRelevance(MultinomialNB())\n",
        "k_vect = TfidfVectorizer()\n",
        "s_vect = TfidfVectorizer()\n",
        "r_vect = TfidfVectorizer()\n",
        "c_transform = ColumnTransformer([('tfidf_k', k_vect, 'knowledge'),('tfidf_s', s_vect, 'seeker'),('tfidf_r', r_vect, 'response')], remainder='passthrough')\n",
        "pipe = Pipeline([('tfidf', c_transform),('classify', modelNb)])\n",
        "pipe.fit(X_train,y_train)\n",
        "res = pipe.predict(X_test)"
      ],
      "metadata": {
        "id": "WOtc4kc-u33K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = classification_report(y_test , res, target_names=[\"Entailment\",\"Generic\",\"Hallucination\",\"Uncooperative\"])\n",
        "cnf_matrix = skm.multilabel_confusion_matrix(y_test, res)\n",
        "print(skm.classification_report(y_test,res))"
      ],
      "metadata": {
        "id": "n5arF5Tju6xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelSVM = BinaryRelevance(LinearSVC(random_state=42))\n",
        "k_vect = TfidfVectorizer()\n",
        "s_vect = TfidfVectorizer()\n",
        "r_vect = TfidfVectorizer()\n",
        "c_transform = ColumnTransformer([('tfidf_k', k_vect, 'knowledge'),('tfidf_s', s_vect, 'seeker'),('tfidf_r', r_vect, 'response')], remainder='passthrough')\n",
        "pipe_1 = Pipeline([('tfidf', c_transform),('classify', modelSVM)])\n",
        "pipe_1.fit(X_train,y_train)\n",
        "res_1 = pipe_1.predict(X_test)"
      ],
      "metadata": {
        "id": "SJMr_rKVu-JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = classification_report(y_test , res, target_names=[\"Entailment\",\"Generic\",\"Hallucination\",\"Uncooperative\"])\n",
        "cnf_matrix = skm.multilabel_confusion_matrix(y_test, res_1)\n",
        "print(skm.classification_report(y_test,res_1))"
      ],
      "metadata": {
        "id": "dcNW7qN0vBOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VRM Classifier"
      ],
      "metadata": {
        "id": "tlcM0MgKreLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = final_train[[\"knowledge\", \"seeker\", \"response\"]]\n",
        "X_test = final_test[[\"knowledge\", \"seeker\", \"response\"]]\n",
        "y_train = final_train[[\"Ack.\",\"Advisement\",\"Disclosure\",\"Edification\",\"Question\"]]\n",
        "y_test = final_test[[\"Ack.\",\"Advisement\",\"Disclosure\",\"Edification\",\"Question\"]]"
      ],
      "metadata": {
        "id": "vaKGH2rXajTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pipeline\n",
        "modelNb = BinaryRelevance(MultinomialNB())\n",
        "k_vect = TfidfVectorizer()\n",
        "s_vect = TfidfVectorizer()\n",
        "r_vect = TfidfVectorizer()\n",
        "c_transform = ColumnTransformer([('tfidf_k', k_vect, 'knowledge'),('tfidf_s', s_vect, 'seeker'),('tfidf_r', r_vect, 'response')], remainder='passthrough')\n",
        "pipe = Pipeline([('tfidf', c_transform),('classify', modelNb)])\n",
        "pipe.fit(X_train,y_train)\n",
        "res = pipe.predict(X_test)"
      ],
      "metadata": {
        "id": "kTzc0UM6akPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = classification_report(y_test , res, target_names=[\"Ack.\",\"Advisement\",\"Disclosure\",\"Edification\",\"Question\"])\n",
        "cnf_matrix = skm.multilabel_confusion_matrix(y_test, res)\n",
        "print(skm.classification_report(y_test,res))"
      ],
      "metadata": {
        "id": "xTJOnwEdlah6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelSVM = BinaryRelevance(LinearSVC(random_state=42))\n",
        "k_vect = TfidfVectorizer()\n",
        "s_vect = TfidfVectorizer()\n",
        "r_vect = TfidfVectorizer()\n",
        "c_transform = ColumnTransformer([('tfidf_k', k_vect, 'knowledge'),('tfidf_s', s_vect, 'seeker'),('tfidf_r', r_vect, 'response')], remainder='passthrough')\n",
        "pipe_1 = Pipeline([('tfidf', c_transform),('classify', modelSVM)])\n",
        "pipe_1.fit(X_train,y_train)\n",
        "res_1 = pipe_1.predict(X_test)"
      ],
      "metadata": {
        "id": "KVgFArEWpEZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = classification_report(y_test , res, target_names=[\"Ack.\",\"Advisement\",\"Disclosure\",\"Edification\",\"Question\"])\n",
        "cnf_matrix = skm.multilabel_confusion_matrix(y_test, res_1)\n",
        "print(skm.classification_report(y_test,res_1))"
      ],
      "metadata": {
        "id": "uulr5Dy0q3J_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}